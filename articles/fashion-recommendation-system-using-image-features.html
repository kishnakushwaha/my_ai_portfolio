<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Title to be replaced for each article -->
<title>Fashion Recommendation System using Image Features | Kishna Kushwaha</title>
<meta content="Article Description" name="description"/>
<!-- Fonts -->
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&amp;display=swap" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css2?family=Fira+Code&amp;display=swap" rel="stylesheet"/>
<!-- Font Awesome -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet"/>
<!-- Highlight.js Theme (VS Code Dark style) -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css" rel="stylesheet"/>
<!-- Custom CSS -->
<link href="../css/style.css" rel="stylesheet"/>
</head>
<body>
<!-- Navigation -->
<header>
<div class="container nav-container">
<a class="logo" href="../index.html">
<div class="logo-circle"></div>
                Kishna Kushwaha
            </a>
<button aria-label="Toggle navigation" class="mobile-menu-btn">
<i class="fas fa-bars"></i>
</button>
<ul class="nav-links">
<li><a href="../index.html">Home</a></li>
<li><a href="../about.html">About</a></li>
<li><a href="../articles.html">Articles</a></li>
<li><a href="../projects/machine_learning.html">Projects</a></li>
<li><a href="../index.html#courses">Recommended Resources</a></li>
<li>
<button aria-label="Search" class="search-trigger-btn nav-link-btn" id="search-trigger">
<i class="fas fa-search"></i>
</button>
</li>
</ul>
</div>
</header>
<main>
<!-- Top Ad Banner -->
<div class="container" style="margin-top:2rem;">
<div class="ad-unit ad-leaderboard">
<span>Advertisement (Leaderboard)</span>
</div>
</div>
<div class="single-article-container">
<!-- Left: Main Content -->
<div class="article-main">
<article class="article-body">
<h1 style="font-size: 2.5rem; line-height: 1.2; font-weight: 800; margin-bottom: 0.5rem; color: #111827;">
                        Fashion Recommendation System using Image Features</h1>
<div class="article-meta-small" style="margin-bottom: 2rem;">Sep 15, 2025 • 5 min read</div>
<!-- Navigation Top -->
<div style="margin-bottom: 2rem; padding-bottom: 1rem; border-bottom: 1px solid #E5E7EB; display: flex; justify-content: space-between;">
<a class="nav-prev" href="generative-ai-model-from-scratch-with-python.html" style="text-decoration: none; color: var(--primary-color); font-weight: 600;">← Previous Article</a>
<a href="../articles.html" style="text-decoration: none; color: var(--text-muted); font-weight: 500;">All Articles</a>
<a class="nav-next" href="recommendation-system-using-python-and-tensorflow.html" style="text-decoration: none; color: var(--primary-color); font-weight: 600;">Next Article →</a>
</div>
<p>A Fashion Recommendation System using Image Features leverages computer vision and <a href="https://amzn.eu/d/3Bgb8IK" rel="noreferrer noopener" target="_blank"><strong>machine learning</strong></a> techniques to analyze fashion items’ visual aspects (like colour, texture, and style) and recommend similar or complementary products to users. So, if you want to learn how to build a Fashion Recommendation System by utilizing image features, this article is for you. In this article, I’ll take you through the task of building a Fashion Recommendation System utilizing Image Features using the Python programming language.</p>
<h2 class="wp-block-heading">Fashion Recommendation System using Image Features: Process We Can Follow</h2>
<p>Building a fashion recommendation system using image features involves several key steps, leveraging both computer vision and machine learning techniques. Below is a detailed process you can follow to build a fashion recommendation system using image features:</p>
<ol class="wp-block-list">
<li>Assemble a diverse dataset of fashion items. This dataset should include a wide variety of items with different colours, patterns, styles, and categories.</li>
<li>Ensure all images are in a consistent format (e.g., JPEG, PNG) and resolution.</li>
<li>Implement a <a href="data-preprocessing-pipeline-using-python.html" rel="noreferrer noopener" target=""><strong>preprocessing</strong></a> function to prepare images for feature extraction.</li>
<li>Choose a pre-trained CNN model such as VGG16, ResNet, or InceptionV3. These models, pre-trained on large datasets like ImageNet, are capable of extracting powerful feature representations from images.</li>
<li>Pass each image through the CNN model to extract features.</li>
<li>Define a metric for measuring the similarity between feature vectors. </li>
<li>Rank the dataset images based on their similarity to the input image and recommend the top N items that are most similar.</li>
<li>Implement a final function that encapsulates the entire process from pre-processing an input image, extracting features, computing similarities, and outputting recommendations.</li>
</ol>
<p>So, the process starts with collecting a dataset of images based on fashionable outfits. I found an ideal dataset for this task. You can download the dataset from <a href="#" rel="noreferrer noopener" style="pointer-events: none; cursor: default; text-decoration: none; color: inherit;"><strong>here</strong></a>.</p>
<h2 class="wp-block-heading">Fashion Recommendation System using Image Features with Python</h2>
<p>Now, let’s get started with the task of building a fashion recommendation system utilizing image features by importing the necessary Python libraries and the <a href="#" rel="noreferrer noopener" style="pointer-events: none; cursor: default; text-decoration: none; color: inherit;"><strong>dataset</strong></a>:</p>
<pre><code class="language-python">from zipfile import ZipFile
import os

zip_file_path = '/content/women fashion.zip'
extraction_directory = '/content/women_fashion/'

if not os.path.exists(extraction_directory):
    os.makedirs(extraction_directory)

with ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extraction_directory)

extracted_files = os.listdir(extraction_directory)
print(extracted_files[:10])</code></pre>
<pre class="wp-block-preformatted"><strong>['women fashion', '__MACOSX']</strong></pre>
<p>In the above code, a zip file named <strong>‘women fashion.zip’</strong> located at the path: <strong>‘/content/women fashion.zip’</strong> on Google Colab is being extracted to a specified directory: <strong>‘/content/women_fashion/’.</strong> Initially, we check if the extraction directory exists, and if it does not, the directory is created using <strong>os.makedirs()</strong>. Then, using Python’s <strong>ZipFile</strong> module, the zip file is opened in read mode, and its contents are extracted to the designated directory.</p>
<p>The zip file contains a directory named women fashion and some metadata used by macOS (__MACOSX). Let’s ignore the macOS metadata and focus on the women fashion directory, listing its contents to understand the types and number of images we have:</p>
<pre><code class="language-python"># correcting the path to include the 'women fashion' directory and listing its contents
extraction_directory_updated = os.path.join(extraction_directory, 'women fashion')

# list the files in the updated directory
extracted_files_updated = os.listdir(extraction_directory_updated)
extracted_files_updated[:10], len(extracted_files_updated)</code></pre>
<pre class="wp-block-preformatted has-small-font-size"><strong>(['black floral saree.jpg',<br/>  'black, sequined dress with thin shoulder straps.jpg',<br/>  'dark blue, knee-length dress with thin straps.jpg',<br/>  'classic black slip dress with a midi length.jpg',<br/>  'black off-shoulder dress with belt.jpg',<br/>  'white, intricately detailed top and a flowing dark blue skirt.jpg',<br/>  'Women-off-the-shoulder-sexy-embroidery-fashion-party-dress-1.png',<br/>  'fitted, off-the-shoulder white dress with horizontal ribbed texture.jpg',<br/>  'one-shoulder, fitted dress that features sequin embellishments and sheer panels.jpg',<br/>  'fitted, short, yellow dress with short sleeves.jpeg'],<br/> 97)</strong></pre>
<p>Now, let’s have a look at the first image from the dataset:</p>
<pre><code class="language-python">from PIL import Image
import matplotlib.pyplot as plt

# function to load and display an image
def display_image(file_path):
    image = Image.open(file_path)
    plt.imshow(image)
    plt.axis('off')
    plt.show()

# display the first image to understand its characteristics
first_image_path = os.path.join(extraction_directory_updated, extracted_files_updated[0])
display_image(first_image_path)</code></pre>
<figure class="wp-block-image aligncenter size-full"><img alt="Fashion Recommendation System using Image Features: display the first image to understand its characteristics" class="wp-image-22524" data-attachment-id="22524" data-comments-opened="1" data-image-caption="" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="fashion-recommendations-1" data-orig-size="343,389" data-recalc-dims="1" decoding="async" height="389" sizes="(max-width: 343px) 100vw, 343px" src="../assets/datasets/fashion-recommendations-1.png" width="343"/></figure>
<p>Now, we will create a list of all image file paths that will be used later in extracting the features from every image in the dataset:</p>
<pre><code class="language-python">import glob

# directory path containing your images
image_directory = '/content/women_fashion/women fashion'

image_paths_list = [file for file in glob.glob(os.path.join(image_directory, '*.*')) if file.endswith(('.jpg', '.png', '.jpeg', 'webp'))]

# print the list of image file paths
print(image_paths_list)</code></pre>
<p>In the above code, the <strong>glob</strong> module is used to generate a list of file paths for images stored in the directory. The <strong>glob.glob</strong> function searches for files that match a specified pattern, in this case, *.*, which matches all files within the directory. The list comprehension then filters these files to include only those with specific image file extensions (.jpg, .png, .jpeg, .webp). </p>
<p>It ensures that image_paths_list contains paths to only the image files, excluding any other file types that might be present in the directory.</p>
<p>Now, we will extract features from all the fashion images:</p>
<pre><code class="language-python">from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.models import Model
import numpy as np

base_model = VGG16(weights='imagenet', include_top=False)
model = Model(inputs=base_model.input, outputs=base_model.output)

def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array_expanded = np.expand_dims(img_array, axis=0)
    return preprocess_input(img_array_expanded)

def extract_features(model, preprocessed_img):
    features = model.predict(preprocessed_img)
    flattened_features = features.flatten()
    normalized_features = flattened_features / np.linalg.norm(flattened_features)
    return normalized_features

all_features = []
all_image_names = []

for img_path in image_paths_list:
    preprocessed_img = preprocess_image(img_path)
    features = extract_features(model, preprocessed_img)
    all_features.append(features)
    all_image_names.append(os.path.basename(img_path))</code></pre>
<pre class="wp-block-preformatted has-small-font-size"><strong>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5<br/>58889256/58889256 [==============================] - 0s 0us/step<br/>1/1 [==============================] - 1s 715ms/step<br/>1/1 [==============================] - 0s 486ms/step<br/>1/1 [==============================] - 0s 463ms/step<br/>1/1 [==============================] - 1s 623ms/step<br/>1/1 [==============================] - 1s 840ms/step<br/>1/1 [==============================] - 1s 747ms/step<br/>1/1 [==============================] - 1s 583ms/step<br/>1/1 [==============================] - 0s 463ms/step<br/>1/1 [==============================] - 0s 463ms/step<br/>1/1 [==============================] - 0s 471ms/step<br/>1/1 [==============================] - 1s 509ms/step<br/>1/1 [==============================] - 0s 457ms/step<br/>1/1 [==============================] - 0s 474ms/step<br/>1/1 [==============================] - 0s 459ms/step<br/>1/1 [==============================] - 0s 481ms/step<br/>1/1 [==============================] - 0s 465ms/step<br/>1/1 [==============================] - 0s 486ms/step<br/>1/1 [==============================] - 1s 678ms/step<br/>1/1 [==============================] - 1s 846ms/step<br/>1/1 [==============================] - 1s 1s/step<br/>1/1 [==============================] - 1s 760ms/step<br/>1/1 [==============================] - 1s 810ms/step<br/>1/1 [==============================] - 1s 832ms/step<br/>1/1 [==============================] - 1s 796ms/step<br/>1/1 [==============================] - 1s 598ms/step<br/>1/1 [==============================] - 0s 461ms/step<br/>1/1 [==============================] - 0s 472ms/step<br/>1/1 [==============================] - 0s 461ms/step<br/>1/1 [==============================] - 0s 477ms/step<br/>1/1 [==============================] - 0s 481ms/step<br/>1/1 [==============================] - 0s 473ms/step<br/>1/1 [==============================] - 0s 466ms/step<br/>1/1 [==============================] - 0s 476ms/step<br/>1/1 [==============================] - 0s 468ms/step<br/>1/1 [==============================] - 0s 479ms/step<br/>1/1 [==============================] - 0s 471ms/step<br/>1/1 [==============================] - 1s 605ms/step<br/>1/1 [==============================] - 1s 548ms/step<br/>1/1 [==============================] - 1s 679ms/step<br/>1/1 [==============================] - 1s 703ms/step<br/>1/1 [==============================] - 1s 596ms/step<br/>1/1 [==============================] - 1s 1s/step<br/>1/1 [==============================] - 1s 1s/step<br/>1/1 [==============================] - 1s 590ms/step<br/>1/1 [==============================] - 0s 462ms/step<br/>1/1 [==============================] - 0s 482ms/step<br/>1/1 [==============================] - 0s 464ms/step<br/>1/1 [==============================] - 0s 470ms/step<br/>1/1 [==============================] - 0s 484ms/step<br/>1/1 [==============================] - 0s 467ms/step<br/>1/1 [==============================] - 0s 483ms/step<br/>1/1 [==============================] - 0s 464ms/step<br/>1/1 [==============================] - 0s 481ms/step<br/>1/1 [==============================] - 0s 463ms/step<br/>1/1 [==============================] - 0s 479ms/step<br/>1/1 [==============================] - 0s 464ms/step<br/>1/1 [==============================] - 0s 499ms/step<br/>1/1 [==============================] - 0s 466ms/step<br/>1/1 [==============================] - 1s 735ms/step<br/>1/1 [==============================] - 1s 894ms/step<br/>1/1 [==============================] - 2s 2s/step<br/>1/1 [==============================] - 1s 1s/step<br/>1/1 [==============================] - 1s 852ms/step<br/>1/1 [==============================] - 1s 912ms/step<br/>1/1 [==============================] - 1s 1s/step<br/>1/1 [==============================] - 1s 908ms/step<br/>1/1 [==============================] - 1s 871ms/step<br/>1/1 [==============================] - 1s 1s/step<br/>1/1 [==============================] - 1s 579ms/step<br/>1/1 [==============================] - 0s 471ms/step<br/>1/1 [==============================] - 0s 462ms/step<br/>1/1 [==============================] - 0s 466ms/step<br/>1/1 [==============================] - 1s 574ms/step<br/>1/1 [==============================] - 1s 807ms/step<br/>1/1 [==============================] - 1s 809ms/step<br/>1/1 [==============================] - 1s 608ms/step<br/>1/1 [==============================] - 0s 460ms/step<br/>1/1 [==============================] - 0s 467ms/step<br/>1/1 [==============================] - 0s 468ms/step<br/>1/1 [==============================] - 0s 463ms/step<br/>1/1 [==============================] - 0s 474ms/step<br/>1/1 [==============================] - 0s 478ms/step<br/>1/1 [==============================] - 0s 477ms/step<br/>1/1 [==============================] - 0s 469ms/step<br/>1/1 [==============================] - 0s 475ms/step<br/>1/1 [==============================] - 0s 463ms/step<br/>1/1 [==============================] - 0s 479ms/step<br/>1/1 [==============================] - 0s 462ms/step<br/>1/1 [==============================] - 0s 485ms/step<br/>1/1 [==============================] - 0s 471ms/step<br/>1/1 [==============================] - 0s 480ms/step<br/>1/1 [==============================] - 0s 462ms/step<br/>1/1 [==============================] - 0s 476ms/step<br/>1/1 [==============================] - 0s 466ms/step<br/>1/1 [==============================] - 1s 692ms/step<br/>1/1 [==============================] - 1s 848ms/step</strong></pre>
<p>In the above code, a feature extraction process is implemented using the VGG16 model, a popular convolutional neural network pre-trained on the ImageNet dataset, to extract visual features from images stored in image_paths_list.</p>
<p><strong>Initially, the VGG16 model is loaded without its top classification layer (include_top=False), making it suitable for feature extraction rather than classification.</strong> Each image path from image_paths_list is processed through a series of steps: the image is loaded and resized to <strong>224×224</strong> pixels to match the VGG16 input size requirements, converted to a <strong><a href="#" style="pointer-events: none; cursor: default; text-decoration: none; color: inherit;">NumPy</a></strong> array, and preprocessed to fit the model’s expected input format.</p>
<p>The preprocessed images are then fed into the VGG16 model to extract features, which are subsequently flattened and normalized to create a consistent feature vector for each image. These feature vectors (all_features) and their corresponding image filenames (all_image_names) are stored, providing a structured dataset for the next steps in building a fashion recommendation system using image features.</p>
<p>Now, I’ll write a function to recommend fashion images based on image features:</p>
<pre><code class="language-python">from scipy.spatial.distance import cosine

def recommend_fashion_items_cnn(input_image_path, all_features, all_image_names, model, top_n=5):
    # pre-process the input image and extract features
    preprocessed_img = preprocess_image(input_image_path)
    input_features = extract_features(model, preprocessed_img)

    # calculate similarities and find the top N similar images
    similarities = [1 - cosine(input_features, other_feature) for other_feature in all_features]
    similar_indices = np.argsort(similarities)[-top_n:]

    # filter out the input image index from similar_indices
    similar_indices = [idx for idx in similar_indices if idx != all_image_names.index(input_image_path)]

    # display the input image
    plt.figure(figsize=(15, 10))
    plt.subplot(1, top_n + 1, 1)
    plt.imshow(Image.open(input_image_path))
    plt.title("Input Image")
    plt.axis('off')

    # display similar images
    for i, idx in enumerate(similar_indices[:top_n], start=1):
        image_path = os.path.join('/content/women_fashion/women fashion', all_image_names[idx])
        plt.subplot(1, top_n + 1, i + 1)
        plt.imshow(Image.open(image_path))
        plt.title(f"Recommendation {i}")
        plt.axis('off')

    plt.tight_layout()
    plt.show()</code></pre>
<p>In the above code, we defined a function <strong>recommend_fashion_items_cnn</strong>, which recommends fashion items similar to a given input image using deep learning-based feature extraction. It utilizes the VGG16 model to extract high-dimensional feature vectors from images, capturing their visual essence.</p>
<p>For a specified input image, the function preprocesses the image, extracts its features, and calculates the cosine similarity between this feature vector and those of other images in the dataset (all_features). It ranks these images based on similarity and selects the top N most similar images to recommend, explicitly excluding the input image from being recommended to itself by filtering out its index from the list of similar indices.</p>
<p>In the end, the function will visualize the input image and its recommendations by displaying them.</p>
<p>Now, here’s how we can use this function to recommend images based on a similar fashion in the input image:</p>
<pre><code class="language-python">input_image_path = '/content/women_fashion/women fashion/dark, elegant, sleeveless dress that reaches down to about mid-calf.jpg'
recommend_fashion_items_cnn(input_image_path, all_features, image_paths_list, model, top_n=4)</code></pre>
<figure class="wp-block-image aligncenter size-large"><img alt="Fashion Recommendation System using Image Features with Python: output" class="wp-image-22530" data-attachment-id="22530" data-comments-opened="1" data-image-caption="" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="fashion-recommendations-2" data-orig-size="1193,465" data-recalc-dims="1" decoding="async" height="399" sizes="(max-width: 1024px) 100vw, 1024px" src="../assets/datasets/fashion-recommendations-2.png" width="1024"/></figure>
<p>You need to give the path of an image as an input, and you will see similar fashion recommendations as output.</p>
<h3 class="wp-block-heading">Summary</h3>
<p>So, this is how you can build a Fashion Recommendation System using Image Features using the Python programming language. A Fashion Recommendation System using Image Features leverages computer vision and machine learning techniques to analyze fashion items’ visual aspects (like colour, texture, and style) and recommend similar or complementary products to users.</p>
<!-- CONTENT END 1 -->
</article>
<!-- Navigation Bottom -->
<div style="margin-top: 4rem; padding-top: 2rem; border-top: 1px solid #E5E7EB; display: flex; justify-content: space-between;">
<a href="generative-ai-model-from-scratch-with-python.html" style="text-decoration: none; color: var(--primary-color); font-weight: 600;">←
                        Previous Article</a>
<a href="../articles.html" style="text-decoration: none; color: var(--text-muted); font-weight: 500;">All Articles</a>
<a href="recommendation-system-using-python-and-tensorflow.html" style="text-decoration: none; color: var(--primary-color); font-weight: 600;">Next
                        Article →</a>
</div>
</div>
<!-- Right: Sticky Sidebar -->
<aside class="sidebar-area">
<div class="sticky-sidebar-content">
<!-- Search Widget (Optional) -->
<!-- <div class="sidebar-widget"> ... </div> -->
<!-- Sidebar Ad -->
<div class="ad-unit ad-sidebar-vertical">
<span>Advertisement (Vertical)</span>
</div>
<!-- Popular Posts -->
<div class="sidebar-widget">
<h3 class="widget-title">Popular Articles</h3>
<ul class="popular-posts-list">
<li><a href="#">Building AI Agents with LangChain</a></li>
<li><a href="#">Optimizing PyTorch Loops</a></li>
<li><a href="#">Data Structures for ML Engineers</a></li>
</ul>
</div>
</div>
</aside>
</div>
</main>
<!-- Footer -->
<footer class="main-footer">
<div class="container">
<div class="footer-content">
<p>© 2025 Kishna Kushwaha. All rights reserved.</p>
<div class="footer-links">
<a href="#">Privacy Policy</a>
<a href="#">Terms of Service</a>
</div>
</div>
</div>
<a aria-label="Go to top" class="go-top-btn" href="#"><i class="fas fa-arrow-up"></i></a>
</footer>
<script src="../js/script.js"></script>
<script src="../js/search.js"></script>
<!-- Highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
<!-- Search Overlay -->
<div class="search-overlay" id="search-overlay">
<div class="search-container">
<button class="search-close-btn" id="search-close">×</button>
<input autocomplete="off" id="search-input" placeholder="Search articles, projects..." type="text"/>
<div class="search-results" id="search-results"></div>
</div>
</div>
</body>
</html>
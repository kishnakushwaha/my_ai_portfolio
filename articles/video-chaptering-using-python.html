<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<!-- Title to be replaced for each article -->
<title>Video Chaptering using Python | Kishna Kushwaha</title>
<meta content="Article Description" name="description"/>
<!-- Fonts -->
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&amp;display=swap" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css2?family=Fira+Code&amp;display=swap" rel="stylesheet"/>
<!-- Font Awesome -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet"/>
<!-- Highlight.js Theme (VS Code Dark style) -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css" rel="stylesheet"/>
<!-- Custom CSS -->
<link href="../css/style.css" rel="stylesheet"/>
</head>
<body>
<!-- Navigation -->
<header>
<div class="container nav-container">
<a class="logo" href="../index.html">
<div class="logo-circle"></div>
                Kishna Kushwaha
            </a>
<button aria-label="Toggle navigation" class="mobile-menu-btn">
<i class="fas fa-bars"></i>
</button>
<ul class="nav-links">
<li><a href="../index.html">Home</a></li>
<li><a href="../about.html">About</a></li>
<li><a href="../articles.html">Articles</a></li>
<li><a href="../projects/machine_learning.html">Projects</a></li>
<li><a href="../index.html#courses">Recommended Resources</a></li>
<li>
<button aria-label="Search" class="search-trigger-btn nav-link-btn" id="search-trigger">
<i class="fas fa-search"></i>
</button>
</li>
</ul>
</div>
</header>
<main>
<!-- Top Ad Banner -->
<div class="container" style="margin-top:2rem;">
<div class="ad-unit ad-leaderboard">
<span>Advertisement (Leaderboard)</span>
</div>
</div>
<div class="single-article-container">
<!-- Left: Main Content -->
<div class="article-main">
<article class="article-body">
<h1 style="font-size: 2.5rem; line-height: 1.2; font-weight: 800; margin-bottom: 0.5rem; color: #111827;">
                        Video Chaptering using Python</h1>
<div class="article-meta-small" style="margin-bottom: 2rem;">Nov 14, 2025 • 5 min read</div>
<!-- Navigation Top -->
<div style="margin-bottom: 2rem; padding-bottom: 1rem; border-bottom: 1px solid #E5E7EB; display: flex; justify-content: space-between;">
<a class="nav-prev" href="mlops-pipeline-using-apache-airflow.html" style="text-decoration: none; color: var(--primary-color); font-weight: 600;">← Previous Article</a>
<a href="../articles.html" style="text-decoration: none; color: var(--text-muted); font-weight: 500;">All Articles</a>
<a class="nav-next" href="fine-tuning-llms-guide.html" style="text-decoration: none; color: var(--primary-color); font-weight: 600;">Next Article →</a>
</div>
<p>You must have seen video chapters in a YouTube video. Video chaptering is the process of dividing a video into distinct segments, each labelled with a specific title or chapter name, to enhance navigation and user experience. So, if you want to learn how to add video chapters to a video, this article is for you. In this article, I’ll take you through the task of Video Chaptering using Python.</p>
<h2 class="wp-block-heading">Video Chaptering: Getting Started</h2>
<p>Video Chaptering involves using <strong><a href="#" style="pointer-events: none; cursor: default; text-decoration: none; color: inherit;">natural language processing</a></strong> (NLP) and <strong><a href="https://amzn.eu/d/3Bgb8IK">machine learning</a></strong> techniques to automatically segment videos into coherent chapters based on their content. Expected results include structured and easily navigable videos to enhance the user experience by allowing viewers to quickly find and jump to specific sections of interest.</p>
<p>It works by transcribing the audio content of the video and analyzing the text for key topics, themes, and transitions. So, to get started with Video Chaptering, we need to collect audio data from a video and transcribe it to divide it into chapters.</p>
<p>I’ll collect data from a YouTube video for this task, for which we need to use the YouTube data API. You can follow the steps below to sign up and get access to the YouTube data API:</p>
<ol class="wp-block-list">
<li>Go to <strong><a href="https://console.cloud.google.com/welcome?project=precise-data-392110&amp;pli=1" rel="noreferrer noopener" target="_blank">Google Cloud Console</a></strong>.</li>
<li>Click on the project drop-down at the top, then “New Project”.</li>
<li>Enter a project name and click “Create”.</li>
<li>In the Google Cloud Console, navigate to “APIs &amp; Services” &gt; “Library”.</li>
<li>Search for “YouTube Data API v3” and click on it.</li>
<li>Click “Enable”.</li>
<li>Go to “APIs &amp; Services” &gt; “Credentials”.</li>
<li>Click “+ CREATE CREDENTIALS” and select “API key”.</li>
<li>Copy the generated API key.</li>
</ol>
<p>If you find any issues while generating the API, feel free to reach me on <strong><a href="https://www.instagram.com/amankharwal.official/" rel="noreferrer noopener" target="_blank">Instagram</a></strong> or <strong><a href="https://www.linkedin.com/in/aman-kharwal/" rel="noreferrer noopener" target="_blank">LinkedIn</a></strong>.</p>
<h2 class="wp-block-heading">Video Chaptering using Python</h2>
<p>Now, let’s get started with video chaptering by collecting the data from a YouTube video using Python. Below is how we can collect data from a YouTube video by using the YouTube Data API and save the transcribed data into a CSV file:</p>
<pre><code class="language-python">import re
import csv
import pandas as pd
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi

API_KEY = 'Your API Key'

def get_video_id(url):
    # extract video id from the URL
    video_id_match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11}).*', url)
    return video_id_match.group(1) if video_id_match else None

def get_video_title(video_id):
    # build the youTube service
    youtube = build('youtube', 'v3', developerKey=API_KEY)

    # fetch the video details
    request = youtube.videos().list(
        part='snippet',
        id=video_id
    )
    response = request.execute()

    # extract the title
    title = response['items'][0]['snippet']['title'] if response['items'] else 'Unknown Title'
    return title

def get_video_transcript(video_id):
    # fetch the transcript
    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        return transcript
    except Exception as e:
        print(f"An error occurred: {e}")
        return []

def save_to_csv(title, transcript, filename):
    # save the title and transcript to a CSV file
    transcript_data = [{'start': entry['start'], 'text': entry['text']} for entry in transcript]
    df = pd.DataFrame(transcript_data)
    df.to_csv(filename, index=False)

    # save the title separately
    with open(filename, 'a', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['Title:', title])

def main():
    url = input('Enter the YouTube video link: ')
    video_id = get_video_id(url)

    if not video_id:
        print('Invalid YouTube URL.')
        return

    title = get_video_title(video_id)
    transcript = get_video_transcript(video_id)

    if not transcript:
        print('No transcript available for this video.')
        return

    filename = f"{video_id}_transcript.csv"
    save_to_csv(title, transcript, filename)
    print(f'Transcript saved to {filename}')

if __name__ == '__main__':
    main()</code></pre>
<pre class="wp-block-preformatted has-small-font-size"><strong>Enter the YouTube video link: https://youtu.be/71op1DQ2gyo?si=tvMFyTqlQiDDjBj2<br/>Transcript saved to 71op1DQ2gyo_transcript.csv</strong></pre>
<p>The above code extracts the transcript of a YouTube video along with its title and saves it to a CSV file. It starts by extracting the video ID from a provided YouTube URL and then uses the YouTube Data API to fetch the video’s title. Next, it retrieves the video’s transcript using the YouTube Transcript API. The title and transcript data are then saved to a CSV file, with the transcript entries listed alongside their start times. If the transcript retrieval is successful, the file is saved with a name derived from the video ID.</p>
<p>Now, let’s explore this collected dataset:</p>
<pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.decomposition import NMF, LatentDirichletAllocation

# load the dataset
transcript_df = pd.read_csv("/content/71op1DQ2gyo_transcript.csv")
print(transcript_df.head())</code></pre>
<pre class="wp-block-preformatted has-small-font-size"><strong>   start                                     text<br/>0   0.04   in this video I'm going to explain how<br/>1  1.439  to train for Pure muscle growth and I'm<br/>2   3.36            going to lay out five crucial<br/>3   4.96     bodybuilding principles that must be<br/>4   6.68       followed to maximize your muscular</strong></pre>
<pre><code class="language-python">transcript_df['start'] = pd.to_numeric(transcript_df['start'], errors='coerce')

print("Dataset Overview:")
print(transcript_df.info())
print("\nBasic Statistics:")
print(transcript_df.describe())</code></pre>
<pre class="wp-block-preformatted has-small-font-size"><strong>Dataset Overview:<br/>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 461 entries, 0 to 460<br/>Data columns (total 2 columns):<br/> #   Column  Non-Null Count  Dtype  <br/>---  ------  --------------  -----  <br/> 0   start   460 non-null    float64<br/> 1   text    461 non-null    object <br/>dtypes: float64(1), object(1)<br/>memory usage: 7.3+ KB<br/>None<br/><br/>Basic Statistics:<br/>            start<br/>count  460.000000<br/>mean   445.849439<br/>std    252.363844<br/>min      0.040000<br/>25%    223.509250<br/>50%    452.100000<br/>75%    665.970000<br/>max    868.920000</strong></pre>
<p>Let’s have a look at the distribution of the text lengths in each row:</p>
<pre><code class="language-python"># distribution of text lengths
transcript_df['text_length'] = transcript_df['text'].apply(len)
plt.figure(figsize=(10, 5))
plt.hist(transcript_df['text_length'], bins=50, color='blue', alpha=0.7)
plt.title('Distribution of Text Lengths')
plt.xlabel('Text Length')
plt.ylabel('Frequency')
plt.show()</code></pre>
<figure class="wp-block-image aligncenter size-full"><img alt="Video Chaptering: Distribution of Text Lengths" class="wp-image-23925" data-attachment-id="23925" data-comments-opened="1" data-image-caption="" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="video-chapter-1" data-orig-size="841,470" data-recalc-dims="1" decoding="async" height="470" sizes="(max-width: 841px) 100vw, 841px" src="../assets/datasets/video-chapter-1.png" width="841"/></figure>
<p>Now, let’s have a look at the most common words used in the video:</p>
<pre><code class="language-python"># most common words
vectorizer = CountVectorizer(stop_words='english')
word_counts = vectorizer.fit_transform(transcript_df['text'])
word_counts_df = pd.DataFrame(word_counts.toarray(), columns=vectorizer.get_feature_names_out())
common_words = word_counts_df.sum().sort_values(ascending=False).head(20)
plt.figure(figsize=(10, 5))
common_words.plot(kind='bar', color='green', alpha=0.7)
plt.title('Top 20 Common Words')
plt.xlabel('Words')
plt.ylabel('Frequency')
plt.show()</code></pre>
<figure class="wp-block-image aligncenter size-full"><img alt="Top 20 Common Words" class="wp-image-23927" data-attachment-id="23927" data-comments-opened="1" data-image-caption="" data-image-description="" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="video-chapters-2" data-orig-size="841,546" data-recalc-dims="1" decoding="async" height="546" sizes="(max-width: 841px) 100vw, 841px" src="../assets/datasets/video-chapters-2.png" width="841"/></figure>
<p>The next step is to perform topic modelling on this dataset to identify key topics and transitions:</p>
<pre><code class="language-python"># topic Modeling using NMF
n_features = 1000
n_topics = 10
n_top_words = 10

tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')
tf = tf_vectorizer.fit_transform(transcript_df['text'])
nmf = NMF(n_components=n_topics, random_state=42).fit(tf)
tf_feature_names = tf_vectorizer.get_feature_names_out()

def display_topics(model, feature_names, no_top_words):
    topics = []
    for topic_idx, topic in enumerate(model.components_):
        topic_words = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]
        topics.append(" ".join(topic_words))
    return topics

topics = display_topics(nmf, tf_feature_names, n_top_words)
print("\nIdentified Topics:")
for i, topic in enumerate(topics):
    print(f"Topic {i + 1}: {topic}")</code></pre>
<pre class="wp-block-preformatted has-small-font-size"><strong>Identified Topics:
Topic 1: muscle growth maximize pure good target train going better need
Topic 2: week month pre order add body day doing build 10
Topic 3: tension target causes king rope exercise muscles technique example muscle
Topic 4: failure way closer rep going shy really set better high
Topic 5: bodybuilding program want pure new pre technique order use principles
Topic 6: reps weight tank adding type add effective really case free
Topic 7: exercises squat like bench month barbell cable high think squats
Topic 8: sets hard push need maximize volume pull recovery body minute
Topic 9: range motion need means using example use try usually shown
Topic 10: training important ll hypertrophy strength resistance deep volume pure stretch</strong></pre>
<p>In the above code, we are performing topic modelling on the text data using <strong>Non-negative Matrix Factorization</strong> (NMF). It starts by defining the number of features and topics and then uses <strong>CountVectorizer</strong> to convert the text data into a matrix of token counts to filter out common English stop words. The NMF model is then fitted to this term-document matrix to identify a specified number of topics. The <strong>display_topics</strong> function extracts and prints the top words associated with each topic, which helps to interpret the main themes in the transcript.</p>
<p>Now, we will assign topics to each text segment:</p>
<pre><code class="language-python"># get topic distribution for each text segment
topic_distribution = nmf.transform(tf)

# align the lengths by trimming the extra row in topic_distribution
topic_distribution_trimmed = topic_distribution[:len(transcript_df)]

# compute the dominant topic for each text segment
transcript_df['dominant_topic'] = topic_distribution_trimmed.argmax(axis=1)</code></pre>
<p>In the above code, we are assigning topics to each text segment in the transcript based on the previously fitted <strong>NMF</strong> model. It starts by transforming the term-document matrix into a topic distribution for each text segment using the NMF model. It then ensures that the lengths of the topic distribution and the transcript dataframe match by trimming any extra rows in the topic distribution. Finally, it computes the dominant topic for each text segment by finding the topic with the highest value in the topic distribution and assigns this topic to the corresponding text segment in the transcript dataframe, which stores the results in a new column called ‘<strong>dominant_topic</strong>‘.</p>
<p>Now, we will analyze the content of each text segment to manually identify logical breaks:</p>
<pre><code class="language-python"># analyze the content of each text segment to manually identify logical breaks
logical_breaks = []

for i in range(1, len(transcript_df)):
    if transcript_df['dominant_topic'].iloc[i] != transcript_df['dominant_topic'].iloc[i - 1]:
        logical_breaks.append(transcript_df['start'].iloc[i])</code></pre>
<p>Next, we will consolidate the logical breaks into broader chapters:</p>
<pre><code class="language-python"># consolidate the logical breaks into broader chapters
threshold = 60  # seconds
consolidated_breaks = []
last_break = None

for break_point in logical_breaks:
    if last_break is None or break_point - last_break &gt;= threshold:
        consolidated_breaks.append(break_point)
        last_break = break_point</code></pre>
<p>Next, we need to merge consecutive breaks with the same dominant topic:</p>
<pre><code class="language-python"># merge consecutive breaks with the same dominant topic
final_chapters = []
last_chapter = (consolidated_breaks[0], transcript_df['dominant_topic'][0])

for break_point in consolidated_breaks[1:]:
    current_topic = transcript_df[transcript_df['start'] == break_point]['dominant_topic'].values[0]
    if current_topic == last_chapter[1]:
        last_chapter = (last_chapter[0], current_topic)
    else:
        final_chapters.append(last_chapter)
        last_chapter = (break_point, current_topic)

final_chapters.append(last_chapter)  # append the last chapter</code></pre>
<p>In the above code, we are consolidating the chapter breaks by merging consecutive breaks that share the same dominant topic. It initializes the first chapter with the first break point and its corresponding topic. For each subsequent breakpoint, it checks if the dominant topic of the current segment is the same as the previous one. If they match, it continues the current chapter; if they differ, it finalizes the current chapter and starts a new one with the current breakpoint and topic. After processing all breakpoints, it ensures the final chapter is added to the list of chapters. This results in a list of chapters where each chapter consists of continuous segments with the same dominant topic.</p>
<p>Now, we will see the final video chapters according to the time stamps:</p>
<pre><code class="language-python"># Convert the final chapters to a readable time format
chapter_points = []
chapter_names = []

for i, (break_point, topic_idx) in enumerate(final_chapters):
    chapter_time = pd.to_datetime(break_point, unit='s').strftime('%H:%M:%S')
    chapter_points.append(chapter_time)

    # get the context for the chapter name
    chapter_text = transcript_df[(transcript_df['start'] &gt;= break_point) &amp; (transcript_df['dominant_topic'] == topic_idx)]['text'].str.cat(sep=' ')

    # extract key phrases to create a chapter name
    vectorizer = TfidfVectorizer(stop_words='english', max_features=3)
    tfidf_matrix = vectorizer.fit_transform([chapter_text])
    feature_names = vectorizer.get_feature_names_out()
    chapter_name = " ".join(feature_names)

    chapter_names.append(f"Chapter {i+1}: {chapter_name}")

# display the final chapter points with names
print("\nFinal Chapter Points with Names:")
for time, name in zip(chapter_points, chapter_names):
    print(f"{time} - {name}")</code></pre>
<pre class="wp-block-preformatted has-small-font-size"><strong>Final Chapter Points with Names:<br/>00:00:01 - Chapter 1: failure going way<br/>00:01:02 - Chapter 2: bodybuilding program want<br/>00:02:02 - Chapter 3: motion need range<br/>00:03:02 - Chapter 4: exercises fatigue high<br/>00:04:04 - Chapter 5: hard push sets<br/>00:05:06 - Chapter 6: hypertrophy ll training<br/>00:06:08 - Chapter 7: failure really way<br/>00:07:09 - Chapter 8: growth muscle target<br/>00:09:15 - Chapter 9: biceps exercise tension<br/>00:11:16 - Chapter 10: exercises guys month<br/>00:12:19 - Chapter 11: bodybuilding program want<br/>00:13:21 - Chapter 12: arm dedicated included<br/>00:14:21 - Chapter 13: guys thank</strong></pre>
<p>In the above code, we are converting the final chapter breakpoints into a readable time format and generating meaningful names for each chapter. For each chapter breakpoint, it converts the breakpoint from seconds into a formatted time string and adds it to the <strong>chapter_points</strong> list. It then concatenates the text of all segments within the chapter to form the chapter text. Then, by using <strong>TF-IDF vectorization</strong>, it extracts the top three key phrases from this text to create a concise chapter name, which is appended to the <strong>chapter_names</strong> list. Finally, it prints the chapter points along with their generated names to provide a clear and readable structure for the video chapters.</p>
<h3 class="wp-block-heading">Summary</h3>
<p>So, this is how Video Chaptering works. Video chaptering is the process of dividing a video into distinct segments, each labelled with a specific title or chapter name, to enhance navigation and user experience.</p>
<!-- CONTENT END 1 -->
</article>
<!-- Navigation Bottom -->
<div style="margin-top: 4rem; padding-top: 2rem; border-top: 1px solid #E5E7EB; display: flex; justify-content: space-between;">
<a href="mlops-pipeline-using-apache-airflow.html" style="text-decoration: none; color: var(--primary-color); font-weight: 600;">←
                        Previous Article</a>
<a href="../articles.html" style="text-decoration: none; color: var(--text-muted); font-weight: 500;">All Articles</a>
<a href="fine-tuning-llms-guide.html" style="text-decoration: none; color: var(--primary-color); font-weight: 600;">Next
                        Article →</a>
</div>
</div>
<!-- Right: Sticky Sidebar -->
<aside class="sidebar-area">
<div class="sticky-sidebar-content">
<!-- Search Widget (Optional) -->
<!-- <div class="sidebar-widget"> ... </div> -->
<!-- Sidebar Ad -->
<div class="ad-unit ad-sidebar-vertical">
<span>Advertisement (Vertical)</span>
</div>
<!-- Popular Posts -->
<div class="sidebar-widget">
<h3 class="widget-title">Popular Articles</h3>
<ul class="popular-posts-list">
<li><a href="#">Building AI Agents with LangChain</a></li>
<li><a href="#">Optimizing PyTorch Loops</a></li>
<li><a href="#">Data Structures for ML Engineers</a></li>
</ul>
</div>
</div>
</aside>
</div>
</main>
<!-- Footer -->
<footer class="main-footer">
<div class="container">
<div class="footer-content">
<p>© 2025 Kishna Kushwaha. All rights reserved.</p>
<div class="footer-links">
<a href="#">Privacy Policy</a>
<a href="#">Terms of Service</a>
</div>
</div>
</div>
<a aria-label="Go to top" class="go-top-btn" href="#"><i class="fas fa-arrow-up"></i></a>
</footer>
<script src="../js/script.js"></script>
<script src="../js/search.js"></script>
<!-- Highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
<!-- Search Overlay -->
<div class="search-overlay" id="search-overlay">
<div class="search-container">
<button class="search-close-btn" id="search-close">×</button>
<input autocomplete="off" id="search-input" placeholder="Search articles, projects..." type="text"/>
<div class="search-results" id="search-results"></div>
</div>
</div>
</body>
</html>